{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import MinMaxScaler to scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import LogisticRegression for model1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import KNeighborsClassifier for model2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import for decision tree for model3\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4231       80.0     81.0           0  \n",
       "4232       60.0     79.0           1  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_data = pd.read_csv('heart_disease_data.csv')\n",
    "\n",
    "hd_data = hd_data.dropna(axis='columns',how='all')\n",
    "hd_data = hd_data.dropna()\n",
    "hd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hd_data.drop('TenYearCHD', axis=1)\n",
    "y = hd_data['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27.93</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>154.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>25.14</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>67.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.88</td>\n",
       "      <td>83.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "804      1   47        2.0              0         0.0     0.0   \n",
       "2557     0   50        1.0              1        20.0     0.0   \n",
       "3238     1   42        1.0              0         0.0     0.0   \n",
       "2758     0   54        1.0              0         0.0     0.0   \n",
       "63       0   57        1.0              1         3.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "804                 0             1         0    219.0  132.0   91.0  27.93   \n",
       "2557                0             1         0    248.0  154.5  104.0  19.88   \n",
       "3238                0             1         0    327.0  134.0   93.0  25.14   \n",
       "2758                0             0         0    208.0  138.0   78.0  30.47   \n",
       "63                  0             0         0    235.0  126.5   80.0  24.88   \n",
       "\n",
       "      heartRate  glucose  \n",
       "804        75.0     80.0  \n",
       "2557       75.0     87.0  \n",
       "3238       70.0     72.0  \n",
       "2758       67.0     73.0  \n",
       "63         83.0     72.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2742, 15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2324\n",
       "1     418\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(class_weight='balanced')\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.650255288110868\n",
      "Testing Data Score: 0.6301969365426696\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {LR.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_train)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [.01,.1,1,10], 'penalty':['l1','l2','elasticnet']}\n",
    "# Train the model with GridSearch\n",
    "grid = GridSearchCV(LR,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.617, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.614, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.599, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.01, penalty=l2, score=0.675, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.635, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.608, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, penalty=l2, score=0.582, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.688, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.615, total=   0.1s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.638, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.617, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.593, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.662, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.639, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.641, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.612, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.588, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.659, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.644, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.9s finished\n",
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629833938281946"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849015317286652"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf = rf.fit(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {'min_samples_leaf':[1,2,3,4],\n",
    "           'max_depth':[3,5,7,9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(rf,param_rf,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.843, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.852, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.842, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.856, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.850, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.851, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.843, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.843, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.854, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.845, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.854, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.852, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.834, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.852, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.843, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.850, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.845, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.843, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.851, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.843, total=   0.1s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.843, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=40, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 7, 9],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 1}\n",
      "0.8490161275311449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = grid_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       775\n",
      "           1       0.50      0.01      0.03       139\n",
      "\n",
      "    accuracy                           0.85       914\n",
      "   macro avg       0.67      0.51      0.47       914\n",
      "weighted avg       0.80      0.85      0.78       914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
