{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import MinMaxScaler to scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import LogisticRegression for model1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import KNeighborsClassifier for model2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import for decision tree for model3\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4231       80.0     81.0           0  \n",
       "4232       60.0     79.0           1  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_data = pd.read_csv('heart_disease_data.csv')\n",
    "\n",
    "hd_data = hd_data.dropna(axis='columns',how='all')\n",
    "hd_data = hd_data.dropna()\n",
    "hd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hd_data.drop('TenYearCHD', axis=1)\n",
    "y = hd_data['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27.93</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>154.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>25.14</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>67.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.88</td>\n",
       "      <td>83.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "804      1   47        2.0              0         0.0     0.0   \n",
       "2557     0   50        1.0              1        20.0     0.0   \n",
       "3238     1   42        1.0              0         0.0     0.0   \n",
       "2758     0   54        1.0              0         0.0     0.0   \n",
       "63       0   57        1.0              1         3.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "804                 0             1         0    219.0  132.0   91.0  27.93   \n",
       "2557                0             1         0    248.0  154.5  104.0  19.88   \n",
       "3238                0             1         0    327.0  134.0   93.0  25.14   \n",
       "2758                0             0         0    208.0  138.0   78.0  30.47   \n",
       "63                  0             0         0    235.0  126.5   80.0  24.88   \n",
       "\n",
       "      heartRate  glucose  \n",
       "804        75.0     80.0  \n",
       "2557       75.0     87.0  \n",
       "3238       70.0     72.0  \n",
       "2758       67.0     73.0  \n",
       "63         83.0     72.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2742, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2324\n",
       "1     418\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(class_weight='balanced')\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6487964989059081\n",
      "Testing Data Score: 0.6291028446389497\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {LR.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_train)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [.01,.1,1,10], 'penalty':['l1','l2','elasticnet']}\n",
    "# Train the model with GridSearch\n",
    "grid = GridSearchCV(LR,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.617, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.601, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.01, penalty=l2, score=0.595, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.692, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.635, total=   0.1s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, penalty=l2, score=0.614, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.599, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, penalty=l2, score=0.617, total=   0.1s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.610, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.591, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.659, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.659, total=   0.1s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.648, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.593, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.659, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.648, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.6s finished\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(class_weight='balanced'),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6309288287928949"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457330415754923"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=40, class_weight=\"balanced\")\n",
    "rf = rf.fit(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {'min_samples_leaf':[1,2,3,4],\n",
    "           'max_depth':[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(rf,param_rf,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.709, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.729, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.668, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.737, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.690, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.699, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.747, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.717, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.737, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.710, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.683, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.709, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.682, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.741, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.717, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.692, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.721, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.686, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.728, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.712, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "grid_fit = grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 2}\n",
      "0.7220999029423105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid_fit.best_params_)\n",
    "print(grid_fit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = grid_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    596\n",
       "1    318\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions_rf).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80       775\n",
      "           1       0.28      0.65      0.39       139\n",
      "\n",
      "    accuracy                           0.70       914\n",
      "   macro avg       0.60      0.68      0.60       914\n",
      "weighted avg       0.82      0.70      0.74       914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.87116400e-02, 2.47117700e-01, 4.02354686e-02, 1.24355243e-02,\n",
       "       4.24538594e-02, 3.18739701e-03, 1.10017446e-04, 6.08801626e-02,\n",
       "       7.39749335e-03, 7.46838647e-02, 1.82086362e-01, 1.06427556e-01,\n",
       "       6.54564163e-02, 4.60291069e-02, 7.27874313e-02])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = grid_fit.best_estimator_.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male = 0.03871164002636211\n",
      "age = 0.2471176999361883\n",
      "education = 0.040235468552618614\n",
      "currentSmoker = 0.012435524315388562\n",
      "cigsPerDay = 0.04245385942622088\n",
      "BPMeds = 0.003187397011014096\n",
      "prevalentStroke = 0.00011001744563350707\n",
      "prevalentHyp = 0.06088016256741994\n",
      "diabetes = 0.007397493351721364\n",
      "totChol = 0.07468386467752884\n",
      "sysBP = 0.1820863621605198\n",
      "diaBP = 0.10642755607613093\n",
      "BMI = 0.06545641627014125\n",
      "heartRate = 0.04602910693176853\n",
      "glucose = 0.07278743125134329\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(X.columns, importances):\n",
    "    print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age\n",
    "sysBP\n",
    "diaBP\n",
    "glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features by their importance\n",
    "importance_zip = sorted(zip(importances, X), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': [24.71176999361883], 'sysBP': [18.20863621605198], 'diaBP': [10.642755607613093], 'totChol': [7.468386467752884], 'glucose': [7.278743125134329], 'BMI': [6.545641627014125], 'prevalentHyp': [6.0880162567419935], 'heartRate': [4.602910693176853], 'cigsPerDay': [4.245385942622089], 'education': [4.023546855261861], 'male': [3.871164002636211], 'currentSmoker': [1.2435524315388562], 'diabetes': [0.7397493351721364], 'BPMeds': [0.3187397011014096], 'prevalentStroke': [0.011001744563350707]}\n"
     ]
    }
   ],
   "source": [
    "# Python code to convert into dictionary \n",
    "  \n",
    "def Convert(tup, di): \n",
    "    for a, b in tup: \n",
    "        di.setdefault(b, []).append(a * 100) \n",
    "    return di \n",
    "      \n",
    "# Driver Code     \n",
    "\n",
    "dictionary = {} \n",
    "print (Convert(importance_zip, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [24.71176999361883],\n",
       " 'sysBP': [18.20863621605198],\n",
       " 'diaBP': [10.642755607613093],\n",
       " 'totChol': [7.468386467752884],\n",
       " 'glucose': [7.278743125134329],\n",
       " 'BMI': [6.545641627014125],\n",
       " 'prevalentHyp': [6.0880162567419935],\n",
       " 'heartRate': [4.602910693176853],\n",
       " 'cigsPerDay': [4.245385942622089],\n",
       " 'education': [4.023546855261861],\n",
       " 'male': [3.871164002636211],\n",
       " 'currentSmoker': [1.2435524315388562],\n",
       " 'diabetes': [0.7397493351721364],\n",
       " 'BPMeds': [0.3187397011014096],\n",
       " 'prevalentStroke': [0.011001744563350707]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>totChol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>education</th>\n",
       "      <th>male</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.71177</td>\n",
       "      <td>18.208636</td>\n",
       "      <td>10.642756</td>\n",
       "      <td>7.468386</td>\n",
       "      <td>7.278743</td>\n",
       "      <td>6.545642</td>\n",
       "      <td>6.088016</td>\n",
       "      <td>4.602911</td>\n",
       "      <td>4.245386</td>\n",
       "      <td>4.023547</td>\n",
       "      <td>3.871164</td>\n",
       "      <td>1.243552</td>\n",
       "      <td>0.739749</td>\n",
       "      <td>0.31874</td>\n",
       "      <td>0.011002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age      sysBP      diaBP   totChol   glucose       BMI  prevalentHyp  \\\n",
       "0  24.71177  18.208636  10.642756  7.468386  7.278743  6.545642      6.088016   \n",
       "\n",
       "   heartRate  cigsPerDay  education      male  currentSmoker  diabetes  \\\n",
       "0   4.602911    4.245386   4.023547  3.871164       1.243552  0.739749   \n",
       "\n",
       "    BPMeds  prevalentStroke  \n",
       "0  0.31874         0.011002  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_importance = pd.DataFrame(dictionary)\n",
    "ft_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_importance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row0_col0\" class=\"data row0 col0\" >24.71%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row1\" class=\"row_heading level0 row1\" >sysBP</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row1_col0\" class=\"data row1 col0\" >18.21%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row2\" class=\"row_heading level0 row2\" >diaBP</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row2_col0\" class=\"data row2 col0\" >10.64%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row3\" class=\"row_heading level0 row3\" >totChol</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row3_col0\" class=\"data row3 col0\" >7.47%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row4\" class=\"row_heading level0 row4\" >glucose</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row4_col0\" class=\"data row4 col0\" >7.28%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row5\" class=\"row_heading level0 row5\" >BMI</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row5_col0\" class=\"data row5 col0\" >6.55%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row6\" class=\"row_heading level0 row6\" >prevalentHyp</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row6_col0\" class=\"data row6 col0\" >6.09%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row7\" class=\"row_heading level0 row7\" >heartRate</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row7_col0\" class=\"data row7 col0\" >4.60%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row8\" class=\"row_heading level0 row8\" >cigsPerDay</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row8_col0\" class=\"data row8 col0\" >4.25%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row9\" class=\"row_heading level0 row9\" >education</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row9_col0\" class=\"data row9 col0\" >4.02%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row10\" class=\"row_heading level0 row10\" >male</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row10_col0\" class=\"data row10 col0\" >3.87%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row11\" class=\"row_heading level0 row11\" >currentSmoker</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row11_col0\" class=\"data row11 col0\" >1.24%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row12\" class=\"row_heading level0 row12\" >diabetes</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row12_col0\" class=\"data row12 col0\" >0.74%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row13\" class=\"row_heading level0 row13\" >BPMeds</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row13_col0\" class=\"data row13 col0\" >0.32%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024level0_row14\" class=\"row_heading level0 row14\" >prevalentStroke</th>\n",
       "                        <td id=\"T_52d038fa_c920_11ea_819b_9cb6d0d41024row14_col0\" class=\"data row14 col0\" >0.01%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14b5f2ede20>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = ft_importance.transpose().style.format('{0:,.2f}%')\n",
    "formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
