{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\owner\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import MinMaxScaler to scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import LogisticRegression for model1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import KNeighborsClassifier for model2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import for decision tree for model3\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4231       80.0     81.0           0  \n",
       "4232       60.0     79.0           1  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_data = pd.read_csv('heart_disease_data.csv')\n",
    "\n",
    "hd_data = hd_data.dropna(axis='columns',how='all')\n",
    "hd_data = hd_data.dropna()\n",
    "hd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hd_data.drop('TenYearCHD', axis=1)\n",
    "y = hd_data['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27.93</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>154.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>25.14</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>67.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.88</td>\n",
       "      <td>83.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "804      1   47        2.0              0         0.0     0.0   \n",
       "2557     0   50        1.0              1        20.0     0.0   \n",
       "3238     1   42        1.0              0         0.0     0.0   \n",
       "2758     0   54        1.0              0         0.0     0.0   \n",
       "63       0   57        1.0              1         3.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "804                 0             1         0    219.0  132.0   91.0  27.93   \n",
       "2557                0             1         0    248.0  154.5  104.0  19.88   \n",
       "3238                0             1         0    327.0  134.0   93.0  25.14   \n",
       "2758                0             0         0    208.0  138.0   78.0  30.47   \n",
       "63                  0             0         0    235.0  126.5   80.0  24.88   \n",
       "\n",
       "      heartRate  glucose  \n",
       "804        75.0     80.0  \n",
       "2557       75.0     87.0  \n",
       "3238       70.0     72.0  \n",
       "2758       67.0     73.0  \n",
       "63         83.0     72.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2742, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2324\n",
       "1     418\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(class_weight='balanced')\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6487964989059081\n",
      "Testing Data Score: 0.6291028446389497\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {LR.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      "First 10 Actual labels: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_train)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:100]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [.01,.1,1,10], 'penalty':['l1','l2','elasticnet']}\n",
    "# Train the model with GridSearch\n",
    "grid = GridSearchCV(LR,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .................... C=0.01, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.617, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.601, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=0.01, penalty=l2, score=0.595, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.692, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] .................. C=0.01, penalty=l2, score=0.635, total=   0.1s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV] ............ C=0.01, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ..................... C=0.1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, penalty=l2, score=0.614, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.599, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................... C=0.1, penalty=l2, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, penalty=l2, score=0.617, total=   0.1s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ............. C=0.1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.610, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.591, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.659, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.659, total=   0.1s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] ............... C=1, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.648, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.607, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.593, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.659, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.648, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] .............. C=10, penalty=elasticnet, score=nan, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.6s finished\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(class_weight='balanced'),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6309288287928949"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838074398249453"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf = rf.fit(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {'min_samples_leaf':[1,2,3,4],\n",
    "           'max_depth':[3,5,7,9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(rf,param_rf,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.847, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.849, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=1, score=0.849, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.847, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.849, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=2, score=0.849, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.2s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.847, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=3, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=3, min_samples_leaf=4, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.845, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=1, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.850, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.847, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=2, score=0.849, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.849, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.849, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.847, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.847, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=3, score=0.849, total=   0.1s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.845, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.851, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.850, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.847, total=   0.2s\n",
      "[CV] max_depth=5, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=5, min_samples_leaf=4, score=0.847, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.849, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.852, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.854, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.843, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=1, score=0.850, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.849, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.849, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.854, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.843, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=2, score=0.843, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.845, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.852, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.856, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.843, total=   0.1s\n",
      "[CV] max_depth=7, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=3, score=0.845, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.849, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.847, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.854, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.845, total=   0.2s\n",
      "[CV] max_depth=7, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=7, min_samples_leaf=4, score=0.847, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.840, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.849, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.849, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.841, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=1 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=1, score=0.843, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.847, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.852, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.850, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.843, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=2 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=2, score=0.843, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.847, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.854, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.850, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.843, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=3 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=3, score=0.841, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.849, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.851, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.852, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.843, total=   0.2s\n",
      "[CV] max_depth=9, min_samples_leaf=4 .................................\n",
      "[CV] ..... max_depth=9, min_samples_leaf=4, score=0.847, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "grid_fit = grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_samples_leaf': 1}\n",
      "0.8497440602023587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid_fit.best_params_)\n",
    "print(grid_fit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = grid_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       775\n",
      "           1       0.43      0.02      0.04       139\n",
      "\n",
      "    accuracy                           0.85       914\n",
      "   macro avg       0.64      0.51      0.48       914\n",
      "weighted avg       0.79      0.85      0.78       914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02414439, 0.16909877, 0.03023142, 0.00900277, 0.05923548,\n",
       "       0.00630622, 0.00446295, 0.03328158, 0.00938111, 0.09022984,\n",
       "       0.12975113, 0.14084579, 0.09909458, 0.06402431, 0.13090965])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = grid_fit.best_estimator_.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male = 0.024144391425421283\n",
      "age = 0.16909877444249707\n",
      "education = 0.030231415604820164\n",
      "currentSmoker = 0.00900277262289292\n",
      "cigsPerDay = 0.05923547694840456\n",
      "BPMeds = 0.006306223121677261\n",
      "prevalentStroke = 0.004462948738039426\n",
      "prevalentHyp = 0.03328158302084893\n",
      "diabetes = 0.009381111218582204\n",
      "totChol = 0.09022984216337061\n",
      "sysBP = 0.12975112559840893\n",
      "diaBP = 0.14084578622244082\n",
      "BMI = 0.09909458300995637\n",
      "heartRate = 0.06402431249760497\n",
      "glucose = 0.13090965336503463\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(X.columns, importances):\n",
    "    print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age\n",
    "sysBP\n",
    "diaBP\n",
    "glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features by their importance\n",
    "importance_zip = sorted(zip(importances, X), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': [16.90987744424971], 'diaBP': [14.08457862224408], 'glucose': [13.090965336503462], 'sysBP': [12.975112559840893], 'BMI': [9.909458300995636], 'totChol': [9.022984216337061], 'heartRate': [6.402431249760497], 'cigsPerDay': [5.9235476948404555], 'prevalentHyp': [3.328158302084893], 'education': [3.023141560482016], 'male': [2.414439142542128], 'diabetes': [0.9381111218582203], 'currentSmoker': [0.9002772622892921], 'BPMeds': [0.6306223121677261], 'prevalentStroke': [0.4462948738039426]}\n"
     ]
    }
   ],
   "source": [
    "# Python code to convert into dictionary \n",
    "  \n",
    "def Convert(tup, di): \n",
    "    for a, b in tup: \n",
    "        di.setdefault(b, []).append(a * 100) \n",
    "    return di \n",
    "      \n",
    "# Driver Code     \n",
    "\n",
    "dictionary = {} \n",
    "print (Convert(importance_zip, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [16.90987744424971],\n",
       " 'diaBP': [14.08457862224408],\n",
       " 'glucose': [13.090965336503462],\n",
       " 'sysBP': [12.975112559840893],\n",
       " 'BMI': [9.909458300995636],\n",
       " 'totChol': [9.022984216337061],\n",
       " 'heartRate': [6.402431249760497],\n",
       " 'cigsPerDay': [5.9235476948404555],\n",
       " 'prevalentHyp': [3.328158302084893],\n",
       " 'education': [3.023141560482016],\n",
       " 'male': [2.414439142542128],\n",
       " 'diabetes': [0.9381111218582203],\n",
       " 'currentSmoker': [0.9002772622892921],\n",
       " 'BPMeds': [0.6306223121677261],\n",
       " 'prevalentStroke': [0.4462948738039426]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>totChol</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>education</th>\n",
       "      <th>male</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.909877</td>\n",
       "      <td>14.084579</td>\n",
       "      <td>13.090965</td>\n",
       "      <td>12.975113</td>\n",
       "      <td>9.909458</td>\n",
       "      <td>9.022984</td>\n",
       "      <td>6.402431</td>\n",
       "      <td>5.923548</td>\n",
       "      <td>3.328158</td>\n",
       "      <td>3.023142</td>\n",
       "      <td>2.414439</td>\n",
       "      <td>0.938111</td>\n",
       "      <td>0.900277</td>\n",
       "      <td>0.630622</td>\n",
       "      <td>0.446295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age      diaBP    glucose      sysBP       BMI   totChol  heartRate  \\\n",
       "0  16.909877  14.084579  13.090965  12.975113  9.909458  9.022984   6.402431   \n",
       "\n",
       "   cigsPerDay  prevalentHyp  education      male  diabetes  currentSmoker  \\\n",
       "0    5.923548      3.328158   3.023142  2.414439  0.938111       0.900277   \n",
       "\n",
       "     BPMeds  prevalentStroke  \n",
       "0  0.630622         0.446295  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_importance = pd.DataFrame(dictionary)\n",
    "ft_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_importance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row0_col0\" class=\"data row0 col0\" >16.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row1\" class=\"row_heading level0 row1\" >diaBP</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row1_col0\" class=\"data row1 col0\" >14.08%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row2\" class=\"row_heading level0 row2\" >glucose</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row2_col0\" class=\"data row2 col0\" >13.09%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row3\" class=\"row_heading level0 row3\" >sysBP</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row3_col0\" class=\"data row3 col0\" >12.98%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row4\" class=\"row_heading level0 row4\" >BMI</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row4_col0\" class=\"data row4 col0\" >9.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row5\" class=\"row_heading level0 row5\" >totChol</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row5_col0\" class=\"data row5 col0\" >9.02%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row6\" class=\"row_heading level0 row6\" >heartRate</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row6_col0\" class=\"data row6 col0\" >6.40%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row7\" class=\"row_heading level0 row7\" >cigsPerDay</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row7_col0\" class=\"data row7 col0\" >5.92%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row8\" class=\"row_heading level0 row8\" >prevalentHyp</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row8_col0\" class=\"data row8 col0\" >3.33%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row9\" class=\"row_heading level0 row9\" >education</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row9_col0\" class=\"data row9 col0\" >3.02%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row10\" class=\"row_heading level0 row10\" >male</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row10_col0\" class=\"data row10 col0\" >2.41%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row11\" class=\"row_heading level0 row11\" >diabetes</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row11_col0\" class=\"data row11 col0\" >0.94%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row12\" class=\"row_heading level0 row12\" >currentSmoker</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row12_col0\" class=\"data row12 col0\" >0.90%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row13\" class=\"row_heading level0 row13\" >BPMeds</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row13_col0\" class=\"data row13 col0\" >0.63%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024level0_row14\" class=\"row_heading level0 row14\" >prevalentStroke</th>\n",
       "                        <td id=\"T_11b45ff5_c912_11ea_9824_9cb6d0d41024row14_col0\" class=\"data row14 col0\" >0.45%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14b5f1b97f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = ft_importance.transpose().style.format('{0:,.2f}%')\n",
    "formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
